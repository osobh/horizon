# Streaming

High-performance streaming pipeline framework for GPU-native data processing.

## Overview

The `streaming` crate provides a powerful framework for building high-throughput, low-latency data processing pipelines that can seamlessly leverage GPU acceleration. It's designed for real-time processing of large data streams with zero-copy operations and automatic GPU offloading for compute-intensive tasks.

## Features

- **Zero-Copy Operations**: Minimize memory copies throughout the pipeline
- **GPU Acceleration**: Automatic offloading of suitable operations to GPU
- **Back-Pressure Handling**: Intelligent flow control prevents overwhelming consumers
- **Composable Pipelines**: Build complex processing graphs from simple components
- **Async/Await Native**: Built on Tokio for excellent async performance
- **Type-Safe**: Compile-time type checking for pipeline connections
- **Fault Tolerance**: Automatic retry and error handling
- **Metrics**: Built-in performance monitoring

## Usage

### Basic Pipeline

```rust
use streaming::{Pipeline, Source, Sink};

// Create a pipeline
let pipeline = Pipeline::builder()
    .source(Source::from_channel(input_rx))
    .map(|data| data * 2)
    .filter(|data| data > &100)
    .sink(Sink::to_channel(output_tx))
    .build()?;

// Run the pipeline
pipeline.run().await?;
```

### GPU-Accelerated Processing

```rust
use streaming::{Pipeline, GpuProcessor};

// Create GPU processor
let gpu_processor = GpuProcessor::new(gpu_device)?
    .kernel("process_kernel")
    .block_size(256);

// Build GPU-accelerated pipeline
let pipeline = Pipeline::builder()
    .source(source)
    .batch(1024)  // Batch for GPU efficiency
    .process_gpu(gpu_processor)
    .sink(sink)
    .build()?;
```

### Complex Processing Graphs

```rust
use streaming::{Pipeline, Splitter, Merger};

// Create branching pipeline
let pipeline = Pipeline::builder()
    .source(source)
    .split(|item| {
        // Route based on item properties
        if item.priority == High {
            Branch::A
        } else {
            Branch::B
        }
    })
    .branch_a(|branch| {
        branch
            .map(process_high_priority)
            .buffer(100)
    })
    .branch_b(|branch| {
        branch
            .map(process_low_priority)
            .buffer(1000)
    })
    .merge()
    .sink(sink)
    .build()?;
```

### Custom Processors

```rust
use streaming::{Processor, ProcessorError};

#[derive(Clone)]
struct CustomProcessor {
    threshold: f64,
}

impl Processor<f64, String> for CustomProcessor {
    async fn process(&mut self, input: f64) -> Result<String, ProcessorError> {
        if input > self.threshold {
            Ok(format!("High: {}", input))
        } else {
            Ok(format!("Low: {}", input))
        }
    }
}

// Use in pipeline
let pipeline = Pipeline::builder()
    .source(source)
    .process(CustomProcessor { threshold: 50.0 })
    .sink(sink)
    .build()?;
```

## Stream Sources

Built-in sources:

```rust
// Channel source
let source = Source::from_channel(rx);

// File source
let source = Source::from_file("data.csv")
    .with_delimiter(',');

// Network source
let source = Source::from_tcp("0.0.0.0:8080");

// Kafka source
let source = Source::from_kafka("localhost:9092", "topic");

// Custom source
let source = Source::from_fn(|| async {
    // Generate or fetch data
    Some(data)
});
```

## Stream Sinks

Built-in sinks:

```rust
// Channel sink
let sink = Sink::to_channel(tx);

// File sink
let sink = Sink::to_file("output.json")
    .with_format(Format::Json);

// Network sink
let sink = Sink::to_tcp("remote:8080");

// Database sink
let sink = Sink::to_database(pool)
    .with_batch_size(100);

// Multiple sinks
let sink = Sink::fanout(vec![sink1, sink2, sink3]);
```

## Operators

### Transformation
- `map`: Transform each element
- `flat_map`: Transform and flatten
- `filter`: Keep elements matching predicate
- `filter_map`: Combined filter and map

### Aggregation
- `batch`: Group elements into batches
- `window`: Time or count-based windows
- `reduce`: Aggregate elements
- `scan`: Stateful transformation

### Flow Control
- `buffer`: Add buffering capacity
- `throttle`: Rate limiting
- `debounce`: Deduplicate rapid events
- `timeout`: Add timeouts to operations

## Performance Optimization

### Batching for GPU

```rust
// Optimize GPU utilization with batching
let pipeline = Pipeline::builder()
    .source(source)
    .batch(2048)  // Optimal GPU batch size
    .process_gpu(gpu_processor)
    .sink(sink)
    .build()?;
```

### Zero-Copy Optimization

```rust
use streaming::ZeroCopyBuffer;

// Use zero-copy buffers
let buffer = ZeroCopyBuffer::new(size);
let pipeline = Pipeline::builder()
    .source(source)
    .map_zero_copy(|buf| {
        // In-place transformation
        buf.transform_in_place(|data| *data *= 2);
        buf
    })
    .sink(sink)
    .build()?;
```

### Parallel Processing

```rust
// Parallel processing for CPU-bound tasks
let pipeline = Pipeline::builder()
    .source(source)
    .parallel_map(num_cpus::get(), expensive_computation)
    .sink(sink)
    .build()?;
```

## Monitoring

Built-in metrics:

```rust
use streaming::Metrics;

// Get pipeline metrics
let metrics = pipeline.metrics();
println!("Throughput: {} items/sec", metrics.throughput);
println!("Latency p99: {}ms", metrics.latency_p99_ms);
println!("Queue depth: {}", metrics.queue_depth);

// Export to Prometheus
metrics.export_prometheus();
```

## Error Handling

```rust
use streaming::{Pipeline, ErrorHandler};

// Configure error handling
let pipeline = Pipeline::builder()
    .source(source)
    .map(fallible_operation)
    .on_error(ErrorHandler::retry(3))  // Retry 3 times
    .on_error(ErrorHandler::log())     // Log failures
    .on_error(ErrorHandler::skip())    // Skip failed items
    .sink(sink)
    .build()?;
```

## Testing

Comprehensive test utilities:

```rust
#[cfg(test)]
mod tests {
    use streaming::test::{TestSource, TestSink};

    #[tokio::test]
    async fn test_pipeline() {
        let source = TestSource::from_vec(vec![1, 2, 3, 4, 5]);
        let sink = TestSink::new();

        let pipeline = Pipeline::builder()
            .source(source)
            .map(|x| x * 2)
            .sink(sink.clone())
            .build()
            .unwrap();

        pipeline.run().await.unwrap();

        assert_eq!(sink.received(), vec![2, 4, 6, 8, 10]);
    }
}
```

## Coverage

Current test coverage: 100% (117 tests passing)

All major components thoroughly tested:
- Core pipeline functionality
- All operators
- GPU acceleration paths
- Error handling
- Back-pressure mechanisms

## Performance Benchmarks

Typical performance metrics:
- **Throughput**: 10M+ items/second (simple operations)
- **Latency**: <100Î¼s p99 (without GPU)
- **GPU Batch**: 100M+ items/second (parallel operations)
- **Memory Overhead**: <1KB per pipeline stage

## Configuration

```toml
[streaming]
# Buffer sizes
default_buffer_size = 1000
max_buffer_size = 10000

# GPU settings
gpu_batch_size = 2048
gpu_memory_pool_mb = 1024

# Error handling
max_retries = 3
retry_delay_ms = 100

# Metrics
metrics_interval_secs = 10
export_prometheus = true
```

## Integration

Used throughout StratoSwarm:
- `gpu-agents`: Real-time agent communication
- `evolution-streaming`: Continuous evolution pipelines
- `monitoring`: Metrics collection pipelines
- `consensus`: Vote aggregation streams

## License

MIT