//! Test GPU Optimization with Real Workloads
//!
//! Demonstrates achieving 90% GPU utilization using real CUDA kernels

use anyhow::Result;
use cudarc::driver::{CudaDevice, DevicePtr};
use gpu_agents::utilization::{
    gpu_workload_generator::GpuWorkloadGenerator,
    integrated_optimizer::IntegratedGpuOptimizer,
    nvrtc_kernel_launcher::{NvrtcKernelLauncher, OptimizedKernelBuilder, PatternComplexity},
    real_gpu_metrics::RealGpuMetricsCollector,
};
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::RwLock;

#[tokio::main]
async fn main() -> Result<()> {
    // Initialize logging
    env_logger::Builder::from_default_env()
        .filter_level(log::LevelFilter::Info)
        .init();

    println!("üöÄ GPU Optimization Test with Real Workloads");
    println!("===========================================");
    println!("Testing GPU utilization optimization with actual CUDA kernels\n");

    let device = CudaDevice::new(0)?;

    // Initialize NVML for real metrics
    let nvml = nvml_wrapper::Nvml::init()?;
    println!("‚úÖ NVML initialized successfully");

    // Phase 1: Setup components
    println!("\nüìã Phase 1: Setting up optimization components");
    println!("--------------------------------------------");

    // Create workload generator
    let mut workload_generator = GpuWorkloadGenerator::new(device.clone())?;
    println!("  ‚úì GPU workload generator created");

    // Create NVRTC launcher
    let nvrtc_launcher = Arc::new(NvrtcKernelLauncher::new(device.clone())?);
    println!("  ‚úì NVRTC kernel launcher created");

    // Create kernel builder
    let kernel_builder = OptimizedKernelBuilder::new(nvrtc_launcher.clone());
    println!("  ‚úì Optimized kernel builder created");

    // Create metrics collector
    let metrics_collector = RealGpuMetricsCollector::new(device.clone(), 100)?;
    println!("  ‚úì Real GPU metrics collector created");

    // Create integrated optimizer
    let optimizer = IntegratedGpuOptimizer::new(device.clone()).await?;
    println!("  ‚úì Integrated GPU optimizer created");

    // Phase 2: Compile optimized kernels
    println!("\nüîß Phase 2: Compiling optimized CUDA kernels");
    println!("-------------------------------------------");

    let simple_kernel = kernel_builder
        .build_pattern_matcher(PatternComplexity::Simple)
        .await?;
    println!("  ‚úì Simple pattern matcher compiled: {}", simple_kernel);

    let medium_kernel = kernel_builder
        .build_pattern_matcher(PatternComplexity::Medium)
        .await?;
    println!("  ‚úì Medium pattern matcher compiled: {}", medium_kernel);

    let complex_kernel = kernel_builder
        .build_pattern_matcher(PatternComplexity::Complex)
        .await?;
    println!("  ‚úì Complex pattern matcher compiled: {}", complex_kernel);

    // Compile transformation kernels
    let transforms = vec!["simplify", "optimize"];
    let transform_kernels = kernel_builder
        .build_transformation_pipeline(&transforms)
        .await?;
    println!(
        "  ‚úì Transformation pipeline compiled: {:?}",
        transform_kernels
    );

    // Phase 3: Baseline measurement
    println!("\nüìä Phase 3: Measuring baseline GPU utilization");
    println!("---------------------------------------------");

    // Metrics collection is automatic on each call

    // Run baseline workload
    workload_generator.set_intensity(0.5); // Start with low intensity
    let baseline_start = Instant::now();
    let baseline_stats = workload_generator
        .generate_continuous_workload(Duration::from_secs(5))
        .await?;

    // Get baseline metrics
    tokio::time::sleep(Duration::from_millis(500)).await; // Let metrics settle
    let baseline_metrics = metrics_collector.collect_metrics().await?;

    println!(
        "  Baseline GPU utilization: {:.1}%",
        baseline_metrics.compute_utilization * 100.0
    );
    println!(
        "  Baseline memory bandwidth: {:.1}%",
        baseline_metrics.memory_bandwidth_utilization * 100.0
    );
    println!(
        "  Baseline temperature: {:.1}¬∞C",
        baseline_metrics.temperature_celsius
    );
    println!(
        "  Baseline power usage: {:.1}W",
        baseline_metrics.power_watts
    );
    println!("  Kernels launched: {}", baseline_stats.kernels_submitted);
    println!(
        "  Throughput: {:.1} kernels/sec",
        baseline_stats.kernels_per_second()
    );

    // Phase 4: Start optimization
    println!("\n‚ö° Phase 4: Applying GPU utilization optimization");
    println!("------------------------------------------------");

    // Start the integrated optimizer
    optimizer.start_optimization().await?;
    println!("  ‚úì Optimization engine started");

    // Create adaptive workload task
    let workload_gen = Arc::new(RwLock::new(workload_generator));
    let workload_gen_clone = workload_gen.clone();
    let metrics_collector = Arc::new(metrics_collector);
    let metrics_clone = metrics_collector.clone();

    let adaptive_task = tokio::spawn(async move {
        let mut last_adjustment = Instant::now();

        loop {
            if last_adjustment.elapsed() > Duration::from_secs(2) {
                // Get current metrics
                if let Ok(metrics) = metrics_clone.collect_metrics().await {
                    let current_util = metrics.compute_utilization;

                    // Adjust workload intensity based on utilization
                    let mut gen = workload_gen_clone.write().await;
                    if current_util < 0.85 {
                        // Increase intensity
                        let new_intensity = (gen.intensity * 1.2).min(3.0);
                        gen.set_intensity(new_intensity);
                        println!("  üìà Increased workload intensity to {:.1}x", new_intensity);
                    } else if current_util > 0.95 {
                        // Decrease slightly to avoid overload
                        let new_intensity = (gen.intensity * 0.95).max(0.5);
                        gen.set_intensity(new_intensity);
                        println!("  üìâ Decreased workload intensity to {:.1}x", new_intensity);
                    }
                }

                last_adjustment = Instant::now();
            }

            tokio::time::sleep(Duration::from_millis(100)).await;
        }
    });

    // Run optimized workload
    println!("\n  Running optimized workload for 30 seconds...");
    let optimization_start = Instant::now();
    let mut peak_utilization = 0.0f32;
    let mut samples_above_90 = 0u32;
    let mut total_samples = 0u32;

    while optimization_start.elapsed() < Duration::from_secs(30) {
        // Generate workload
        let stats = workload_gen
            .write()
            .await
            .generate_burst_workload(50)
            .await?;

        // Collect metrics
        let metrics = metrics_collector.collect_metrics().await?;
        let current_util = metrics.compute_utilization;

        total_samples += 1;
        if current_util >= 0.90 {
            samples_above_90 += 1;
        }
        if current_util > peak_utilization {
            peak_utilization = current_util;
        }

        // Progress update
        if total_samples % 10 == 0 {
            println!(
                "  Progress: {:.1}% utilization | Memory: {:.1}% | Power: {:.1}W | Temp: {:.1}¬∞C",
                current_util * 100.0,
                metrics.memory_bandwidth_utilization * 100.0,
                metrics.power_watts,
                metrics.temperature_celsius
            );
        }

        // Check if we've achieved target
        if current_util >= 0.90 && samples_above_90 > 5 {
            println!(
                "\n‚úÖ Target achieved! GPU utilization: {:.1}%",
                current_util * 100.0
            );
        }

        tokio::time::sleep(Duration::from_millis(500)).await;
    }

    // Stop adaptive task
    adaptive_task.abort();

    // Phase 5: Results analysis
    println!("\nüìà Phase 5: Optimization Results");
    println!("-------------------------------");

    let final_report = optimizer.generate_report().await?;
    let nvrtc_stats = nvrtc_launcher.get_stats().await;

    // Calculate success rate
    let success_rate = (samples_above_90 as f32 / total_samples as f32) * 100.0;

    println!("  Peak GPU utilization: {:.1}%", peak_utilization * 100.0);
    println!("  Time at 90%+ utilization: {:.1}%", success_rate);
    println!("  Total samples: {}", total_samples);

    // Get final metrics
    let final_metrics = metrics_collector.collect_metrics().await?;
    let improvement =
        (final_metrics.compute_utilization - baseline_metrics.compute_utilization) * 100.0;

    println!("\n  Performance Improvement:");
    println!("  - GPU utilization: +{:.1} percentage points", improvement);
    println!(
        "  - Final temperature: {:.1}¬∞C",
        final_metrics.temperature_celsius
    );
    println!("  - Final power: {:.1}W", final_metrics.power_watts);

    // Print detailed reports
    println!("\nüìã Detailed Reports:");
    println!("-------------------");
    println!("\n{}", final_report);
    println!("\n{}", nvrtc_stats);

    // Phase 6: Benchmark comparison
    println!("\nüî¨ Phase 6: Performance Comparison");
    println!("---------------------------------");

    // Test with different kernel complexities
    for complexity in [
        PatternComplexity::Simple,
        PatternComplexity::Medium,
        PatternComplexity::Complex,
    ] {
        let kernel_name = kernel_builder.build_pattern_matcher(complexity).await?;

        // Allocate test buffers
        let pattern_buffer = device.alloc_zeros::<u8>(64 * 64)?;
        let ast_buffer = device.alloc_zeros::<u8>(10000 * 64)?;
        let match_buffer = device.alloc_zeros::<u32>(10000 * 2)?;

        let start = Instant::now();

        // Launch kernel multiple times
        for _ in 0..100 {
            nvrtc_launcher
                .launch_pattern_matcher(
                    &kernel_name,
                    *pattern_buffer.device_ptr() as *const u8,
                    *ast_buffer.device_ptr() as *const u8,
                    *match_buffer.device_ptr() as *mut u32,
                    64,
                    10000,
                )
                .await?;
        }

        device.synchronize()?;
        let elapsed = start.elapsed();

        println!(
            "  {:?} kernel: {:.2}ms per launch",
            complexity,
            elapsed.as_secs_f64() * 1000.0 / 100.0
        );
    }

    // Summary
    if success_rate >= 50.0 {
        println!("\nüéâ SUCCESS: GPU optimization achieved target utilization!");
        println!("   The system successfully maintained 90%+ GPU utilization");
        println!("   using real CUDA kernels and dynamic optimization.");
    } else {
        println!(
            "\n‚ö†Ô∏è  Partial success: Peak utilization {:.1}% achieved",
            peak_utilization * 100.0
        );
        println!("   Consider tuning workload parameters for sustained 90%+ utilization.");
    }

    // Cleanup - optimization runs in background and stops automatically

    println!("\n‚úÖ Test completed successfully!");

    Ok(())
}
